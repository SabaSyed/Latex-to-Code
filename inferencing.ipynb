{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c527ae14-aac1-4240-a3ce-3a5a6b3de807",
      "metadata": {
        "id": "c527ae14-aac1-4240-a3ce-3a5a6b3de807",
        "outputId": "ea0521d0-3cca-43db-8d99-52c043e5b4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF_HOME is set to: /workspace\n"
          ]
        }
      ],
      "source": [
        "# Set the environment variable before importing transformers\n",
        "import os\n",
        "os.environ['HF_HOME'] = '/workspace'\n",
        "print(\"HF_HOME is set to:\", os.getenv('HF_HOME'))\n",
        "cache_dir = '/workspace/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634d9bb9-43cc-4203-bf63-d58179d2e997",
      "metadata": {
        "id": "634d9bb9-43cc-4203-bf63-d58179d2e997"
      },
      "outputs": [],
      "source": [
        "rm -rf ~/.cache/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b687024-af8e-4e2e-ae60-d5eec4f7d80b",
      "metadata": {
        "id": "6b687024-af8e-4e2e-ae60-d5eec4f7d80b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, RobertaTokenizer\n",
        "\n",
        "# Load the CodeT5 model\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"./Model\", torch_dtype=torch.float16).to('cuda')\n",
        "\n",
        "# Load the correct tokenizer for CodeT5\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"./Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22d65ef-b810-4c01-bbcf-242ddc717017",
      "metadata": {
        "id": "c22d65ef-b810-4c01-bbcf-242ddc717017",
        "outputId": "13a27934-3702-411e-faff-57f011c810ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32100, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32100, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32100, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d590e0d7-8c19-43cf-8add-bde37bd4a8a1",
      "metadata": {
        "id": "d590e0d7-8c19-43cf-8add-bde37bd4a8a1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "import torch\n",
        "\n",
        "# Fix unmatched brackets\n",
        "def fix_unmatched_brackets(code):\n",
        "    \"\"\"\n",
        "    Fix unmatched brackets in the code by ensuring that all opening brackets have corresponding closing brackets,\n",
        "    and ensure that newline characters are handled correctly when adding missing brackets.\n",
        "    \"\"\"\n",
        "    open_brackets = {'(': 0, '[': 0, '{': 0}\n",
        "    close_brackets = {')': 0, ']': 0, '}': 0}\n",
        "    bracket_pairs = {'(': ')', '[': ']', '{': '}'}\n",
        "\n",
        "    stack = []\n",
        "    new_code = \"\"\n",
        "\n",
        "    # Iterate through the code to track unmatched brackets and their positions\n",
        "    for i, char in enumerate(code):\n",
        "        if char in open_brackets:\n",
        "            stack.append(char)\n",
        "            open_brackets[char] += 1\n",
        "        elif char in close_brackets:\n",
        "            if stack and bracket_pairs[stack[-1]] == char:\n",
        "                stack.pop()  # Matching bracket\n",
        "            else:\n",
        "                # Unmatched closing bracket found, but we need to check if it's valid\n",
        "                if stack:\n",
        "                    # If we have an unmatched opening bracket, fix it by adding the correct closing bracket\n",
        "                    new_code += bracket_pairs[stack.pop()]\n",
        "                else:\n",
        "                    # If no matching opening bracket, just skip adding the closing bracket\n",
        "                    continue\n",
        "        new_code += char\n",
        "\n",
        "    # Append missing closing brackets at the end\n",
        "    while stack:\n",
        "        last_char = new_code[-1]\n",
        "        # If the last character is a newline, remove it before appending the closing bracket\n",
        "        if last_char == '\\n':\n",
        "            new_code = new_code[:-1]\n",
        "        new_code += bracket_pairs[stack.pop()]\n",
        "\n",
        "    return new_code\n",
        "# Validate and correct bracket balance\n",
        "def validate_bracket_balance(code):\n",
        "    \"\"\"\n",
        "    Validates if brackets are balanced and fixes common issues.\n",
        "    \"\"\"\n",
        "    stack = []\n",
        "    bracket_map = {')': '(', ']': '[', '}': '{'}\n",
        "\n",
        "    for i, char in enumerate(code):\n",
        "        if char in bracket_map.values():\n",
        "            stack.append(char)\n",
        "        elif char in bracket_map:\n",
        "            if stack and stack[-1] == bracket_map[char]:\n",
        "                stack.pop()\n",
        "            else:\n",
        "                code = code[:i] + '#' + code[i+1:]  # Comment out the misaligned closing bracket\n",
        "                break\n",
        "\n",
        "    while stack:\n",
        "        code += { '(': ')', '[': ']', '{': '}' }[stack.pop()]\n",
        "\n",
        "    return code\n",
        "\n",
        "# Add missing imports based on used functions\n",
        "def add_missing_imports(code):\n",
        "    \"\"\"\n",
        "    Detect missing sympy or numpy imports based on used functions in the code.\n",
        "    Also fixes incorrect import statements like `from sympy import, pi`.\n",
        "    \"\"\"\n",
        "    sympy_funcs = {\n",
        "        \"cot\", \"sqrt\", \"pi\", \"sin\", \"cos\", \"tan\", \"log\", \"Abs\", \"exp\",\n",
        "        \"factorial\", \"csc\", \"sec\", \"asin\", \"acos\", \"atan\", \"Eq\", \"symbols\", \"Function\", \"Derivative\"\n",
        "    }\n",
        "\n",
        "    # Detect function calls and existing imports\n",
        "    function_pattern = r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b'\n",
        "    used_functions = set(re.findall(function_pattern, code))\n",
        "\n",
        "    # Match 'from sympy import' statements\n",
        "    existing_imports = re.findall(r'from sympy import ([a-zA-Z_, ]+)', code)\n",
        "\n",
        "    # Flatten the existing imports set by splitting any comma-separated imports\n",
        "    existing_imports_set = {imp.strip() for ex_imp in existing_imports for imp in ex_imp.split(',')}\n",
        "\n",
        "    # Find which sympy functions are required but not yet imported\n",
        "    required_imports = used_functions.intersection(sympy_funcs) - existing_imports_set\n",
        "\n",
        "    # If there are required imports, we will just add them on top of the existing imports\n",
        "    if required_imports:\n",
        "        # Consolidate all imports into one line, without adding duplicate imports\n",
        "        import_statement = f\"from sympy import {', '.join(sorted(existing_imports_set | required_imports))}\\n\"\n",
        "\n",
        "        # Remove the current sympy imports with a consolidated import statement\n",
        "        code = re.sub(r'from sympy import [a-zA-Z_, ]+\\n', '', code)\n",
        "        code = import_statement + code\n",
        "\n",
        "    # Fully remove incorrect import statements (like `from sympy import, pi`)\n",
        "    code = re.sub(r'from sympy import,\\s*.*\\n', '', code)\n",
        "\n",
        "    # Add numpy import if necessary\n",
        "    if \"np.\" in code and \"import numpy as np\" not in code:\n",
        "        code = \"import numpy as np\\n\" + code\n",
        "\n",
        "    return code\n",
        "# Enhanced removal of evalf() calls, handling malformed cases\n",
        "def remove_evalf(code):\n",
        "    \"\"\"\n",
        "    Remove all occurrences of .evalf() from the code, including cases where it's misplaced or malformed.\n",
        "    \"\"\"\n",
        "    # Remove evalf calls in a more comprehensive way\n",
        "    code = re.sub(r'\\.evalf\\(\\)', '', code)  # Regular evalf calls\n",
        "    code = re.sub(r'\\*evalf\\(\\)', '', code)  # Cases like `*evalf()`\n",
        "\n",
        "    # Ensure parentheses remain balanced even after removing evalf()\n",
        "    code = fix_unmatched_brackets(code)\n",
        "\n",
        "    return code\n",
        "\n",
        "def handle_sum_errors(code):\n",
        "    \"\"\"\n",
        "    Detects and fixes cases where `sum()` is applied to non-iterable objects.\n",
        "    \"\"\"\n",
        "    # Regex to detect invalid use of sum\n",
        "    invalid_sum_pattern = r'sum\\(([^()]+)\\)'\n",
        "\n",
        "    # Replace invalid sum usage with the content inside the sum (since it's non-iterable)\n",
        "    code = re.sub(invalid_sum_pattern, r'\\1', code)\n",
        "\n",
        "    return code\n",
        "\n",
        "def complete_try_catch_block(code):\n",
        "    \"\"\"\n",
        "    Ensure that the try block in the code is followed by a valid except block.\n",
        "    If missing, a generic except block will be added.\n",
        "    \"\"\"\n",
        "    # Check if there's a 'try' block without an 'except' block\n",
        "    if 'try:' in code and 'except' not in code:\n",
        "        # Add a generic except block to catch any exceptions\n",
        "        code = re.sub(r'try:', r'try:\\n        pass\\n    except Exception as e:\\n        print(f\"Error: {e}\")', code)\n",
        "    return code\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_extra_variables_from_function(code):\n",
        "    \"\"\"\n",
        "    Remove extra variables from the function definition list of arguments\n",
        "    that are not used in the function body.\n",
        "    \"\"\"\n",
        "\n",
        "    # Find the function definition\n",
        "    match = re.search(r'def\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\((.*?)\\):', code)\n",
        "\n",
        "    if match:\n",
        "        func_name = match.group(1)\n",
        "        arg_list = match.group(2).split(',')\n",
        "        arg_list = [arg.strip() for arg in arg_list]  # Clean up spaces\n",
        "\n",
        "        # Get the body of the function (everything after the definition)\n",
        "        func_body = code.split(':', 1)[1]\n",
        "\n",
        "        # Find which variables are actually used in the function body\n",
        "        used_vars = set(re.findall(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b', func_body))\n",
        "\n",
        "        # Filter out only the arguments that are actually used in the function body\n",
        "        filtered_args = [arg for arg in arg_list if arg in used_vars]\n",
        "\n",
        "        # Reconstruct the function definition with only the used arguments\n",
        "        new_func_def = f\"def {func_name}({', '.join(filtered_args)}):\"\n",
        "\n",
        "        # Replace the old function definition with the new one\n",
        "        code = re.sub(r'def\\s+[a-zA-Z_][a-zA-Z0-9_]*\\s*\\(.*?\\):', new_func_def, code)\n",
        "\n",
        "    return code\n",
        "\n",
        "# Post-process the generated code\n",
        "def post_process_code(code):\n",
        "    code = fix_unmatched_brackets(code)\n",
        "    code = validate_bracket_balance(code)\n",
        "    code = add_missing_imports(code)\n",
        "    code = remove_evalf(code)\n",
        "    code = handle_sum_errors(code)\n",
        "    code = complete_try_catch_block(code)\n",
        "    code = remove_extra_variables_from_function(code)\n",
        "    return code\n",
        "\n",
        "# Generate the final code from LaTeX\n",
        "def generate_code(latex_expression, max_length=512):\n",
        "    inputs = tokenizer(f\"Latex Expression: {latex_expression} Solution:\", return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_length=max_length)\n",
        "    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    post_processed_code = post_process_code(generated_code)\n",
        "    return post_processed_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c8a155-a4e5-45a2-b505-8e37daee38d7",
      "metadata": {
        "id": "99c8a155-a4e5-45a2-b505-8e37daee38d7",
        "outputId": "0307bec6-bfd3-4059-ca88-bbf59c472e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated codes saved to formatted_Large.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "def save_generated_code_as_json(test_data, file_path):\n",
        "    results = []\n",
        "\n",
        "    for entry in test_data:\n",
        "        latex_expr = entry.get('latex_expression', '')\n",
        "        generated_code = generate_code(latex_expr)\n",
        "\n",
        "        # Extract the task_id and test_cases from the entry\n",
        "        task_id = entry.get('task_id', None)\n",
        "        test_cases = entry.get('test_cases', [])\n",
        "\n",
        "        results.append({\n",
        "            \"task_id\": task_id,\n",
        "            \"latex_expression\": latex_expr,\n",
        "            \"generated_code\": generated_code,\n",
        "            \"test_cases\": test_cases\n",
        "        })\n",
        "\n",
        "    # Save the results to a JSON file\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "# Define the input and output file paths\n",
        "input_file_path = 'test.json'\n",
        "output_file_path = 'formatted_Large.json'\n",
        "\n",
        "# Load the test dataset\n",
        "with open(input_file_path, 'r') as file:\n",
        "    test_data = json.load(file)\n",
        "\n",
        "# Save the generated codes to the JSON file\n",
        "save_generated_code_as_json(test_data, output_file_path)\n",
        "\n",
        "print(f\"Generated codes saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb56d8e-2240-4853-a1d8-da41c107368c",
      "metadata": {
        "id": "2fb56d8e-2240-4853-a1d8-da41c107368c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import inspect\n",
        "import csv\n",
        "\n",
        "# Load data from formatted_Large_v2.json file\n",
        "with open('formatted_Large.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Collect results\n",
        "results = []\n",
        "for task in data:\n",
        "    code = task['generated_code']\n",
        "    test_cases = task['test_cases']\n",
        "    task_id = task['task_id']\n",
        "    outputs = []\n",
        "\n",
        "    # Define the function from the generated code\n",
        "    try:\n",
        "        namespace = {}\n",
        "        exec(code, namespace)\n",
        "        func_name = code.split('def ')[1].split('(')[0]\n",
        "        func = namespace[func_name]\n",
        "\n",
        "        # Get the parameter names in the correct order from the function definition\n",
        "        param_names = list(inspect.signature(func).parameters.keys())\n",
        "    except Exception as e:\n",
        "        print(f\"Error defining function for task_id {task_id}: {str(e)}\")\n",
        "        func_name = None\n",
        "\n",
        "    if func_name:\n",
        "        for case in test_cases:\n",
        "            inputs = case['input']\n",
        "            try:\n",
        "                # Use only the parameters from the test case that match the function's arguments\n",
        "                ordered_inputs = {param: inputs[param] for param in param_names if param in inputs}\n",
        "\n",
        "                result = func(**ordered_inputs)\n",
        "\n",
        "                # Check if the result has evalf() method and call it if necessary\n",
        "                if hasattr(result, 'evalf'):\n",
        "                    result = result.evalf()\n",
        "\n",
        "                # Format floating-point results to 6 digits after the decimal point\n",
        "                formatted_result = f\"{result:.6f}\"\n",
        "                outputs.append(formatted_result)\n",
        "            except TypeError as e:\n",
        "                if \"got an unexpected keyword argument\" in str(e):\n",
        "                    print(f\"Error processing input {inputs} for task_id: {task_id}\")\n",
        "                    outputs.append(\"inf\")\n",
        "                else:\n",
        "                    outputs.append(None)\n",
        "            except ValueError as e:\n",
        "                if \"math range error\" in str(e):\n",
        "                    outputs.append(\"inf\")\n",
        "                else:\n",
        "                    outputs.append(None)\n",
        "            except OverflowError as e:\n",
        "                if \"math range error\" in str(e):\n",
        "                    outputs.append(\"inf\")\n",
        "                else:\n",
        "                    outputs.append(None)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing input {inputs} for task_id: {task_id}\")\n",
        "                outputs.append(None)\n",
        "    else:\n",
        "        outputs = [None] * len(test_cases)\n",
        "\n",
        "    results.append((task_id, outputs))\n",
        "\n",
        "# Write results to CSV file\n",
        "with open('results.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['id', 'outputs'])\n",
        "    for task_id, outputs in results:\n",
        "        writer.writerow([task_id, outputs])\n",
        "\n",
        "print(\"Results saved to results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d59049-8ec3-4be7-85f5-8fc561431cbc",
      "metadata": {
        "id": "02d59049-8ec3-4be7-85f5-8fc561431cbc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 (llm_bootcamp)",
      "language": "python",
      "name": "llm_bootcamp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
